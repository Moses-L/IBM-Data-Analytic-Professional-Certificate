{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Normalization Techniques**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will focus on data normalization. This includes identifying compensation-related columns, applying normalization techniques, and visualizing the data distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify duplicate rows and remove them.\n",
    "\n",
    "- Check and handle missing values in key columns.\n",
    "\n",
    "- Identify and normalize compensation-related columns.\n",
    "\n",
    "- Visualize the effect of normalization techniques on data distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Install and Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset into a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below will download the dataset into your browser:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to check if data is loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Handling Duplicates\n",
    "##### Task 1: Identify and remove duplicate rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "        ResponseId                      MainBranch                 Age  \\\n",
      "0               1  I am a developer by profession  Under 18 years old   \n",
      "1               2  I am a developer by profession     35-44 years old   \n",
      "2               3  I am a developer by profession     45-54 years old   \n",
      "3               4           I am learning to code     18-24 years old   \n",
      "4               5  I am a developer by profession     18-24 years old   \n",
      "...           ...                             ...                 ...   \n",
      "65432       65433  I am a developer by profession     18-24 years old   \n",
      "65433       65434  I am a developer by profession     25-34 years old   \n",
      "65434       65435  I am a developer by profession     25-34 years old   \n",
      "65435       65436  I am a developer by profession     18-24 years old   \n",
      "65436       65437     I code primarily as a hobby     18-24 years old   \n",
      "\n",
      "                Employment                            RemoteWork   Check  \\\n",
      "0      Employed, full-time                                Remote  Apples   \n",
      "1      Employed, full-time                                Remote  Apples   \n",
      "2      Employed, full-time                                Remote  Apples   \n",
      "3       Student, full-time                                   NaN  Apples   \n",
      "4       Student, full-time                                   NaN  Apples   \n",
      "...                    ...                                   ...     ...   \n",
      "65432  Employed, full-time                                Remote  Apples   \n",
      "65433  Employed, full-time                                Remote  Apples   \n",
      "65434  Employed, full-time                             In-person  Apples   \n",
      "65435  Employed, full-time  Hybrid (some remote, some in-person)  Apples   \n",
      "65436   Student, full-time                                   NaN  Apples   \n",
      "\n",
      "                                        CodingActivities  \\\n",
      "0                                                  Hobby   \n",
      "1      Hobby;Contribute to open-source projects;Other...   \n",
      "2      Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                    NaN   \n",
      "4                                                    NaN   \n",
      "...                                                  ...   \n",
      "65432                      Hobby;School or academic work   \n",
      "65433           Hobby;Contribute to open-source projects   \n",
      "65434                                              Hobby   \n",
      "65435  Hobby;Contribute to open-source projects;Profe...   \n",
      "65436                                                NaN   \n",
      "\n",
      "                                                 EdLevel  \\\n",
      "0                              Primary/elementary school   \n",
      "1           Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2        Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3      Some college/university study without earning ...   \n",
      "4      Secondary school (e.g. American high school, G...   \n",
      "...                                                  ...   \n",
      "65432       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "65433                                                NaN   \n",
      "65434       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "65435  Secondary school (e.g. American high school, G...   \n",
      "65436                                                NaN   \n",
      "\n",
      "                                               LearnCode  \\\n",
      "0                                 Books / Physical media   \n",
      "1      Books / Physical media;Colleague;On the job tr...   \n",
      "2      Books / Physical media;Colleague;On the job tr...   \n",
      "3      Other online resources (e.g., videos, blogs, f...   \n",
      "4      Other online resources (e.g., videos, blogs, f...   \n",
      "...                                                  ...   \n",
      "65432  On the job training;School (i.e., University, ...   \n",
      "65433                                                NaN   \n",
      "65434  Other online resources (e.g., videos, blogs, f...   \n",
      "65435  On the job training;Other online resources (e....   \n",
      "65436                                                NaN   \n",
      "\n",
      "                                         LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                    NaN  ...            NaN   \n",
      "1      Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2      Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3      Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4      Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "...                                                  ...  ...            ...   \n",
      "65432                                                NaN  ...            NaN   \n",
      "65433                                                NaN  ...            NaN   \n",
      "65434  Technical documentation;Stack Overflow;Social ...  ...            NaN   \n",
      "65435  Technical documentation;Blogs;Written Tutorial...  ...            0.0   \n",
      "65436                                                NaN  ...            NaN   \n",
      "\n",
      "      JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0                NaN            NaN            NaN             NaN   \n",
      "1                0.0            0.0            0.0             0.0   \n",
      "2                NaN            NaN            NaN             NaN   \n",
      "3                NaN            NaN            NaN             NaN   \n",
      "4                NaN            NaN            NaN             NaN   \n",
      "...              ...            ...            ...             ...   \n",
      "65432            NaN            NaN            NaN             NaN   \n",
      "65433            NaN            NaN            NaN             NaN   \n",
      "65434            NaN            NaN            NaN             NaN   \n",
      "65435            0.0            0.0            0.0             0.0   \n",
      "65436            NaN            NaN            NaN             NaN   \n",
      "\n",
      "      JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly  \\\n",
      "0                 NaN                    NaN        NaN                 NaN   \n",
      "1                 0.0                    NaN        NaN                 NaN   \n",
      "2                 NaN  Appropriate in length       Easy                 NaN   \n",
      "3                 NaN               Too long       Easy                 NaN   \n",
      "4                 NaN              Too short       Easy                 NaN   \n",
      "...               ...                    ...        ...                 ...   \n",
      "65432             NaN                    NaN        NaN                 NaN   \n",
      "65433             NaN                    NaN        NaN                 NaN   \n",
      "65434             NaN                    NaN        NaN                 NaN   \n",
      "65435             0.0                    NaN        NaN                 NaN   \n",
      "65436             NaN                    NaN        NaN                 NaN   \n",
      "\n",
      "      JobSat  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "...      ...  \n",
      "65432    NaN  \n",
      "65433    NaN  \n",
      "65434    NaN  \n",
      "65435    NaN  \n",
      "65436    NaN  \n",
      "\n",
      "[65437 rows x 114 columns]\n",
      "\n",
      "DataFrame with duplicates removed:\n",
      "        ResponseId                      MainBranch                 Age  \\\n",
      "0               1  I am a developer by profession  Under 18 years old   \n",
      "1               2  I am a developer by profession     35-44 years old   \n",
      "2               3  I am a developer by profession     45-54 years old   \n",
      "3               4           I am learning to code     18-24 years old   \n",
      "4               5  I am a developer by profession     18-24 years old   \n",
      "...           ...                             ...                 ...   \n",
      "65432       65433  I am a developer by profession     18-24 years old   \n",
      "65433       65434  I am a developer by profession     25-34 years old   \n",
      "65434       65435  I am a developer by profession     25-34 years old   \n",
      "65435       65436  I am a developer by profession     18-24 years old   \n",
      "65436       65437     I code primarily as a hobby     18-24 years old   \n",
      "\n",
      "                Employment                            RemoteWork   Check  \\\n",
      "0      Employed, full-time                                Remote  Apples   \n",
      "1      Employed, full-time                                Remote  Apples   \n",
      "2      Employed, full-time                                Remote  Apples   \n",
      "3       Student, full-time                                   NaN  Apples   \n",
      "4       Student, full-time                                   NaN  Apples   \n",
      "...                    ...                                   ...     ...   \n",
      "65432  Employed, full-time                                Remote  Apples   \n",
      "65433  Employed, full-time                                Remote  Apples   \n",
      "65434  Employed, full-time                             In-person  Apples   \n",
      "65435  Employed, full-time  Hybrid (some remote, some in-person)  Apples   \n",
      "65436   Student, full-time                                   NaN  Apples   \n",
      "\n",
      "                                        CodingActivities  \\\n",
      "0                                                  Hobby   \n",
      "1      Hobby;Contribute to open-source projects;Other...   \n",
      "2      Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                    NaN   \n",
      "4                                                    NaN   \n",
      "...                                                  ...   \n",
      "65432                      Hobby;School or academic work   \n",
      "65433           Hobby;Contribute to open-source projects   \n",
      "65434                                              Hobby   \n",
      "65435  Hobby;Contribute to open-source projects;Profe...   \n",
      "65436                                                NaN   \n",
      "\n",
      "                                                 EdLevel  \\\n",
      "0                              Primary/elementary school   \n",
      "1           Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2        Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3      Some college/university study without earning ...   \n",
      "4      Secondary school (e.g. American high school, G...   \n",
      "...                                                  ...   \n",
      "65432       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "65433                                                NaN   \n",
      "65434       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "65435  Secondary school (e.g. American high school, G...   \n",
      "65436                                                NaN   \n",
      "\n",
      "                                               LearnCode  \\\n",
      "0                                 Books / Physical media   \n",
      "1      Books / Physical media;Colleague;On the job tr...   \n",
      "2      Books / Physical media;Colleague;On the job tr...   \n",
      "3      Other online resources (e.g., videos, blogs, f...   \n",
      "4      Other online resources (e.g., videos, blogs, f...   \n",
      "...                                                  ...   \n",
      "65432  On the job training;School (i.e., University, ...   \n",
      "65433                                                NaN   \n",
      "65434  Other online resources (e.g., videos, blogs, f...   \n",
      "65435  On the job training;Other online resources (e....   \n",
      "65436                                                NaN   \n",
      "\n",
      "                                         LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                    NaN  ...            NaN   \n",
      "1      Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2      Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3      Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4      Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "...                                                  ...  ...            ...   \n",
      "65432                                                NaN  ...            NaN   \n",
      "65433                                                NaN  ...            NaN   \n",
      "65434  Technical documentation;Stack Overflow;Social ...  ...            NaN   \n",
      "65435  Technical documentation;Blogs;Written Tutorial...  ...            0.0   \n",
      "65436                                                NaN  ...            NaN   \n",
      "\n",
      "      JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0                NaN            NaN            NaN             NaN   \n",
      "1                0.0            0.0            0.0             0.0   \n",
      "2                NaN            NaN            NaN             NaN   \n",
      "3                NaN            NaN            NaN             NaN   \n",
      "4                NaN            NaN            NaN             NaN   \n",
      "...              ...            ...            ...             ...   \n",
      "65432            NaN            NaN            NaN             NaN   \n",
      "65433            NaN            NaN            NaN             NaN   \n",
      "65434            NaN            NaN            NaN             NaN   \n",
      "65435            0.0            0.0            0.0             0.0   \n",
      "65436            NaN            NaN            NaN             NaN   \n",
      "\n",
      "      JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly  \\\n",
      "0                 NaN                    NaN        NaN                 NaN   \n",
      "1                 0.0                    NaN        NaN                 NaN   \n",
      "2                 NaN  Appropriate in length       Easy                 NaN   \n",
      "3                 NaN               Too long       Easy                 NaN   \n",
      "4                 NaN              Too short       Easy                 NaN   \n",
      "...               ...                    ...        ...                 ...   \n",
      "65432             NaN                    NaN        NaN                 NaN   \n",
      "65433             NaN                    NaN        NaN                 NaN   \n",
      "65434             NaN                    NaN        NaN                 NaN   \n",
      "65435             0.0                    NaN        NaN                 NaN   \n",
      "65436             NaN                    NaN        NaN                 NaN   \n",
      "\n",
      "      JobSat  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "...      ...  \n",
      "65432    NaN  \n",
      "65433    NaN  \n",
      "65434    NaN  \n",
      "65435    NaN  \n",
      "65436    NaN  \n",
      "\n",
      "[65437 rows x 114 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Index(['col2', 'col1'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1286/3134300642.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original DataFrame:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDataFrame with duplicates removed:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_no_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Remove duplicates based on specific columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_no_duplicates_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'col2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Check duplicates in col1 and col2 only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDataFrame with duplicates removed based on subset:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_no_duplicates_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6815\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6816\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6818\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6820\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6946\u001b[0m         \u001b[0;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6947\u001b[0m         \u001b[0;31m# key that doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6948\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6950\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6953\u001b[0m             \u001b[0;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Index(['col2', 'col1'], dtype='object')"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Remove duplicate rows (keeping the first occurrence by default)\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDataFrame with duplicates removed:\\n\", df_no_duplicates)\n",
    "\n",
    "# Remove duplicates based on specific columns\n",
    "df_no_duplicates_subset = df.drop_duplicates(subset=['col1', 'col2']) # Check duplicates in col1 and col2 only\n",
    "\n",
    "print(\"\\nDataFrame with duplicates removed based on subset:\\n\", df_no_duplicates_subset)\n",
    "\n",
    "\n",
    "# Keep the last occurrence of duplicates\n",
    "df_no_duplicates_last = df.drop_duplicates(keep='last')\n",
    "\n",
    "print(\"\\nDataFrame with duplicates removed (keeping last):\\n\", df_no_duplicates_last)\n",
    "\n",
    "# Remove duplicates and modify the original DataFrame (in-place)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"\\nOriginal DataFrame modified in-place:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Handling Missing Values\n",
    "##### Task 2: Identify missing values in `CodingActivities`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values (Boolean):\n",
      " 0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "Name: CodingActivities, dtype: bool\n",
      "\n",
      "Number of Missing Values: 1\n",
      "\n",
      "Rows with Missing Values:\n",
      "    RespondentID CodingActivities\n",
      "4             5              NaN\n",
      "\n",
      "Valid Values (Boolean):\n",
      " 0     True\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "Name: CodingActivities, dtype: bool\n",
      "\n",
      "DataFrame after filling missing values:\n",
      "    RespondentID CodingActivities\n",
      "0             1           Coding\n",
      "1             2              NaN\n",
      "2             3           Coding\n",
      "3             4       Not Coding\n",
      "4             5          Unknown\n",
      "\n",
      "DataFrame after dropping rows with missing values:\n",
      "    RespondentID CodingActivities\n",
      "0             1           Coding\n",
      "1             2              NaN\n",
      "2             3           Coding\n",
      "3             4       Not Coding\n",
      "4             5          Unknown\n",
      "\n",
      "DataFrame after replacing string 'NaN' with numpy NaN:\n",
      "    RespondentID CodingActivities\n",
      "0             1           Coding\n",
      "1             2              NaN\n",
      "2             3           Coding\n",
      "3             4       Not Coding\n",
      "4             5          Unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1286/3739390967.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CodingActivities'].fillna('Unknown', inplace=True)  # Fills missing values with 'Unknown'\n",
      "/tmp/ipykernel_1286/3739390967.py:43: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CodingActivities'].replace({'NaN': np.nan}, inplace=True) # Replace string 'NaN' with actual numpy NaN\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import pandas as pd\n",
    "import numpy as np  # Import numpy for NaN handling (if needed)\n",
    "\n",
    "# Sample data (replace with your actual CodingActivities DataFrame)\n",
    "data = {'RespondentID': [1, 2, 3, 4, 5],\n",
    "        'CodingActivities': ['Coding', 'NaN', 'Coding', 'Not Coding', np.nan]}  # Include NaN\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Identify Missing Values (Various Methods):\n",
    "\n",
    "# a) Using isna() or isnull() (Most Common):\n",
    "missing_values = df['CodingActivities'].isna()  # or df['CodingActivities'].isnull()\n",
    "print(\"Missing Values (Boolean):\\n\", missing_values)\n",
    "\n",
    "# b) Counting Missing Values:\n",
    "num_missing = df['CodingActivities'].isna().sum()\n",
    "print(\"\\nNumber of Missing Values:\", num_missing)\n",
    "\n",
    "# c) Showing Rows with Missing Values:\n",
    "rows_with_missing = df[df['CodingActivities'].isna()]\n",
    "print(\"\\nRows with Missing Values:\\n\", rows_with_missing)\n",
    "\n",
    "# d) Using notna() to find valid values:\n",
    "valid_values = df['CodingActivities'].notna()\n",
    "print(\"\\nValid Values (Boolean):\\n\", valid_values)\n",
    "\n",
    "# 2. Handling Missing Values (Options):\n",
    "\n",
    "# a) Filling with a specific value:\n",
    "df['CodingActivities'].fillna('Unknown', inplace=True)  # Fills missing values with 'Unknown'\n",
    "print(\"\\nDataFrame after filling missing values:\\n\", df)\n",
    "\n",
    "# b) Filling with the mean/median/mode (if appropriate):\n",
    "# (Not applicable in this categorical example; more relevant for numerical data)\n",
    "# For numerical columns:  df['NumericalColumn'].fillna(df['NumericalColumn'].mean(), inplace=True)\n",
    "\n",
    "# c) Dropping rows with missing values:\n",
    "df_no_missing = df.dropna(subset=['CodingActivities'])  # Removes rows where 'CodingActivities' is NaN\n",
    "print(\"\\nDataFrame after dropping rows with missing values:\\n\", df_no_missing)\n",
    "\n",
    "# d) Replacing with numpy.nan (if you want to keep them as NaNs):\n",
    "df['CodingActivities'].replace({'NaN': np.nan}, inplace=True) # Replace string 'NaN' with actual numpy NaN\n",
    "print(\"\\nDataFrame after replacing string 'NaN' with numpy NaN:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3: Impute missing values in CodingActivities with forward-fill.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after forward-fill:\n",
      "    RespondentID CodingActivities\n",
      "0             1           Coding\n",
      "1             2           Coding\n",
      "2             3           Coding\n",
      "3             4       Not Coding\n",
      "4             5       Not Coding\n",
      "5             6       Not Coding\n",
      "6             7           Coding\n",
      "\n",
      "DataFrame after dropping NaNs:\n",
      "    ConvertedCompYearly\n",
      "0             100000.0\n",
      "2             120000.0\n",
      "4             150000.0\n",
      "5             200000.0\n",
      "\n",
      "DataFrame after imputing with median:\n",
      "    ConvertedCompYearly\n",
      "0             100000.0\n",
      "1             135000.0\n",
      "2             120000.0\n",
      "3             135000.0\n",
      "4             150000.0\n",
      "5             200000.0\n",
      "6             135000.0\n",
      "\n",
      "DataFrame after forward-fill:\n",
      "    ConvertedCompYearly\n",
      "0             100000.0\n",
      "1             135000.0\n",
      "2             120000.0\n",
      "3             135000.0\n",
      "4             150000.0\n",
      "5             200000.0\n",
      "6             135000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1286/302960115.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CodingActivities'].replace({'NaN': np.nan}, inplace=True)\n",
      "/tmp/ipykernel_1286/302960115.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df2['ConvertedCompYearly'].fillna(median_comp, inplace=True)  # Fill with median\n",
      "/tmp/ipykernel_1286/302960115.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df2['ConvertedCompYearly'].ffill(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data (replace with your actual CodingActivities DataFrame)\n",
    "data = {'RespondentID': [1, 2, 3, 4, 5, 6, 7],\n",
    "        'CodingActivities': ['Coding', 'NaN', 'Coding', 'Not Coding', np.nan, np.nan, 'Coding']}  # Include NaN\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Replace string \"NaN\" with actual np.nan if needed\n",
    "df['CodingActivities'].replace({'NaN': np.nan}, inplace=True)\n",
    "\n",
    "# 2. Forward-fill missing values in 'CodingActivities'\n",
    "df['CodingActivities'].ffill(inplace=True)  # Forward fill\n",
    "\n",
    "print(\"DataFrame after forward-fill:\\n\", df)\n",
    "\n",
    "\n",
    "\n",
    "# Example with ConvertedCompYearly (handling NaNs before normalizing)\n",
    "data2 = {'ConvertedCompYearly': [100000, np.nan, 120000, np.nan, 150000, 200000, np.nan]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Option 1: Drop rows with NaN in 'ConvertedCompYearly'\n",
    "df2_dropped = df2.dropna(subset=['ConvertedCompYearly'])\n",
    "# Normalize df2_dropped['ConvertedCompYearly'] (code for normalization would go here)\n",
    "print(\"\\nDataFrame after dropping NaNs:\\n\", df2_dropped)\n",
    "\n",
    "\n",
    "# Option 2: Impute with median (or mean)\n",
    "median_comp = df2['ConvertedCompYearly'].median()  # Calculate the median\n",
    "df2['ConvertedCompYearly'].fillna(median_comp, inplace=True)  # Fill with median\n",
    "# Now normalize df2['ConvertedCompYearly'] (code for normalization would go here)\n",
    "print(\"\\nDataFrame after imputing with median:\\n\", df2)\n",
    "\n",
    "# Option 3: Forward fill ConvertedCompYearly\n",
    "df2['ConvertedCompYearly'].ffill(inplace=True)\n",
    "print(\"\\nDataFrame after forward-fill:\\n\", df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:  Before normalizing ConvertedCompYearly, ensure that any missing values (NaN) in this column are handled appropriately. You can choose to either drop the rows containing NaN or replace the missing values with a suitable statistic (e.g., median or mean).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Normalizing Compensation Data\n",
    "##### Task 4: Identify compensation-related columns, such as ConvertedCompYearly.\n",
    "Normalization is commonly applied to compensation data to bring values within a comparable range. Here, you’ll identify ConvertedCompYearly or similar columns, which contain compensation information. This column will be used in the subsequent tasks for normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compensation-related columns:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the local file\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for compensation-related columns\n",
    "compensation_columns = [col for col in df.columns if 'Comp' in col or 'Salary' in col]\n",
    "print(\"Compensation-related columns:\")\n",
    "print(compensation_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvertedCompYearly column not found. Checking for similar columns...\n",
      "No compensation-related columns found.\n",
      "Cannot proceed with normalization without a compensation column.\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import pandas as pd\n",
    "\n",
    "# ... (Load your data into a DataFrame called 'df') ...\n",
    "\n",
    "# 1. Check for 'ConvertedCompYearly' directly:\n",
    "if 'ConvertedCompYearly' in df.columns:\n",
    "    print(\"Found ConvertedCompYearly column.\")\n",
    "    compensation_column = 'ConvertedCompYearly'  # Store the column name\n",
    "else:\n",
    "    print(\"ConvertedCompYearly column not found. Checking for similar columns...\")\n",
    "\n",
    "    # 2. Look for similar column names (case-insensitive):\n",
    "    similar_columns = [col for col in df.columns if 'comp' in col.lower() or 'salary' in col.lower() or 'compensation' in col.lower()]\n",
    "\n",
    "    if similar_columns:\n",
    "        print(\"Found similar columns:\", similar_columns)\n",
    "\n",
    "        # 3. Choose the most appropriate column (or handle multiple columns):\n",
    "        # This will depend on your specific dataset.  Here are some strategies:\n",
    "\n",
    "        # a) If only one similar column is found, use it:\n",
    "        if len(similar_columns) == 1:\n",
    "            compensation_column = similar_columns[0]\n",
    "            print(f\"Using {compensation_column} as the compensation column.\")\n",
    "\n",
    "        # b) If multiple similar columns are found, you might need to:\n",
    "        elif len(similar_columns) > 1:\n",
    "            print(\"Multiple compensation-related columns found.  Choose one or combine them.\")\n",
    "\n",
    "            # i) Print info about the columns to help you decide\n",
    "            for col in similar_columns:\n",
    "                print(f\"\\nColumn: {col}\")\n",
    "                print(df[col].describe())  # Get descriptive statistics\n",
    "                print(df[col].head())      # Show a few values\n",
    "\n",
    "            # ii) Select one (or create a combined compensation column)\n",
    "            # Example: Choose the column that seems to represent yearly compensation\n",
    "            # (Replace with your actual logic)\n",
    "            compensation_column = None\n",
    "            for col in similar_columns:\n",
    "                if 'yearly' in col.lower() or 'annual' in col.lower():  # Look for yearly/annual in name\n",
    "                    compensation_column = col\n",
    "                    break\n",
    "            if compensation_column:\n",
    "                print(f\"Selected {compensation_column} as the primary compensation column.\")\n",
    "            else:\n",
    "                print(\"No suitable yearly compensation column found. Choose one manually from the listed columns.\")\n",
    "\n",
    "            # Example: If you have multiple columns (e.g., base salary, bonus),\n",
    "            # you might create a new 'TotalCompensation' column:\n",
    "            # df['TotalCompensation'] = df['BaseSalary'] + df['Bonus']\n",
    "\n",
    "        else:\n",
    "            print(\"No compensation-related columns found.\")\n",
    "            compensation_column = None  # Or raise an exception if it's essential\n",
    "\n",
    "    else:\n",
    "        print(\"No compensation-related columns found.\")\n",
    "        compensation_column = None  # Or raise an exception if it's essential\n",
    "\n",
    "\n",
    "if compensation_column:  # If a compensation column was identified\n",
    "    print(f\"The column to be normalized is: {compensation_column}\")\n",
    "    # Now proceed with normalization (min-max scaling, standardization, etc.)\n",
    "    # ... your normalization code here ...\n",
    "else:\n",
    "    print(\"Cannot proceed with normalization without a compensation column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 5: Normalize ConvertedCompYearly using Min-Max Scaling.\n",
    "Min-Max Scaling brings all values in a column to a 0-1 range, making it useful for comparing data across different scales. Here, you will apply Min-Max normalization to the ConvertedCompYearly column, creating a new column ConvertedCompYearly_MinMax with normalized values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compensation-related columns:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the local file\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for compensation-related columns\n",
    "compensation_columns = [col for col in df.columns if 'Comp' in col or 'Salary' in col]\n",
    "print(\"Compensation-related columns:\")\n",
    "print(compensation_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6: Apply Z-score Normalization to `ConvertedCompYearly`.\n",
    "\n",
    "Z-score normalization standardizes values by converting them to a distribution with a mean of 0 and a standard deviation of 1. This method is helpful for datasets with a Gaussian (normal) distribution. Here, you’ll calculate Z-scores for the ConvertedCompYearly column, saving the results in a new column ConvertedCompYearly_Zscore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compensation-related columns:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the local file\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for compensation-related columns\n",
    "compensation_columns = [col for col in df.columns if 'Comp' in col or 'Salary' in col]\n",
    "print(\"Compensation-related columns:\")\n",
    "print(compensation_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Visualization of Normalized Data\n",
    "##### Task 7: Visualize the distribution of `ConvertedCompYearly`, `ConvertedCompYearly_Normalized`, and `ConvertedCompYearly_Zscore`\n",
    "\n",
    "Visualization helps you understand how normalization changes the data distribution. In this task, create histograms for the original ConvertedCompYearly, as well as its normalized versions (ConvertedCompYearly_MinMax and ConvertedCompYearly_Zscore). This will help you compare how each normalization technique affects the data range and distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at path: path_to_your_local_file/survey-data.csv\n",
      "Data file could not be loaded. Exiting.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import os\n",
    "\n",
    "file_path = os.path.join('path_to_your_local_file', 'survey-data.csv')  # Replace with your path\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)  # Load the data\n",
    "    file_loaded = True  # Set a flag to indicate successful loading\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at path: {file_path}\")\n",
    "    file_loaded = False  # Set the flag to false\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the CSV: {e}\")\n",
    "    file_loaded = False  # Set the flag to false\n",
    "\n",
    "if file_loaded:  # Proceed ONLY if the file was successfully loaded\n",
    "    # 2. Identify the compensation column\n",
    "    compensation_columns = [\n",
    "        col for col in df.columns if 'comp' in col.lower() or 'salary' in col.lower()\n",
    "    ]\n",
    "\n",
    "    if 'ConvertedCompYearly' in df.columns:\n",
    "        compensation_column = 'ConvertedCompYearly'\n",
    "    elif compensation_columns:\n",
    "        compensation_column = compensation_columns[0]  # Or your selection logic\n",
    "    else:\n",
    "        compensation_column = None\n",
    "\n",
    "    if compensation_column:  # Proceed with normalization and visualization only if compensation column exists\n",
    "        try:\n",
    "            # 3. Handle missing values\n",
    "            df[compensation_column].fillna(df[compensation_column].median(), inplace=True)\n",
    "\n",
    "            # 4. Min-Max Scaling\n",
    "            scaler_minmax = MinMaxScaler()\n",
    "            df[f'{compensation_column}_MinMax'] = scaler_minmax.fit_transform(df[[compensation_column]])\n",
    "\n",
    "            # 5. Z-score Standardization\n",
    "            scaler_zscore = StandardScaler()\n",
    "            df[f'{compensation_column}_Zscore'] = scaler_zscore.fit_transform(df[[compensation_column]])\n",
    "\n",
    "            # 6. Visualization\n",
    "            plt.figure(figsize=(15, 5))\n",
    "\n",
    "            plt.subplot(1, 3, 1)\n",
    "            df[compensation_column].hist(bins=50)\n",
    "            plt.title(f'Original {compensation_column} Distribution')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            df[f'{compensation_column}_MinMax'].hist(bins=50)\n",
    "            plt.title(f'{compensation_column} - Min-Max Scaled')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            df[f'{compensation_column}_Zscore'].hist(bins=50)\n",
    "            plt.title(f'{compensation_column} - Z-score Standardized')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during processing: {e}\")\n",
    "    else:\n",
    "        print(\"No suitable compensation column found. Cannot proceed.\")\n",
    "\n",
    "else:\n",
    "    print(\"Data file could not be loaded. Exiting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you practiced essential normalization techniques, including:\n",
    "\n",
    "- Identifying and handling duplicate rows.\n",
    "\n",
    "- Checking for and imputing missing values.\n",
    "\n",
    "- Applying Min-Max scaling and Z-score normalization to compensation data.\n",
    "\n",
    "- Visualizing the impact of normalization on data distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "5b2314eae200c68d20ee3204d822e6fad4f5845945b4895f383c3007af43740d"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
